{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a1e8380-7325-405a-88b9-50aab734fabb",
   "metadata": {},
   "source": [
    "# ЯЗЫКИ СТАТЕЙ\n",
    "\n",
    "Основные языки, используемые для цитирования в науке – это самые распространенные языки мира. Английский язык является наиболее популярным: на нем разговаривают около 2 миллионов человек, и около 80% всех научных статей написаны на английском (Björk & Solomon, 2012). Другие языки:\n",
    "\n",
    "- **Латынь** – язык терминологии во многих науках и искусствах.\n",
    "- **Русский язык** – язык основной целевой аудитории: в России и странах СНГ многие исследования публикуются на русском, особенно в гуманитарных и социальных науках. Доступ к таким статьям может быть ограничен.\n",
    "- **Испанский, французский, немецкий и китайский** – имеют значительное количество публикаций, особенно в локальных журналах.\n",
    "\n",
    "**Аргументация:** Приложение должно поддерживать несколько языков, чтобы обеспечить доступность для широкой аудитории. Это позволит охватить более широкий спектр пользователей и увеличить количество статей для резюмирования.\n",
    "\n",
    "# ТЕМАТИКИ\n",
    "\n",
    "Ежедневно публикуются миллионы статей, блогов и научных работ в различных областях. Эти области можно объединить по критериям, и суммаризатор должен уметь различать типы статей и классифицировать их по предметам исследований:\n",
    "\n",
    "- **Естественные науки** (химия, биология, физика)\n",
    "- **Технические науки** (инженерия, информатика, робототехника)\n",
    "- **Социальные науки** (психология, социология, экономика) – исследования человеческого поведения и социальных структур\n",
    "- **Медицинские науки** – охватывают клинические исследования, фармакологию, эпидемиологию; содержат много статистических данных, что усложняет анализ.\n",
    "\n",
    "**Аргументация:** Каждая тематика требует специфического подхода к резюмированию. Например, в естественных науках важно сохранять точность терминов, в то время как в социальных науках может быть важнее передать контекст исследования.\n",
    "\n",
    "# ПРОБЛЕМЫ В ДАННЫХ\n",
    "\n",
    "1. **Разнообразие форматов:** Научные статьи могут быть в разных форматах (PDF, DOCX), что затрудняет автоматическое извлечение текста.\n",
    "2. **Качество данных:** Не все статьи имеют структурированные аннотации или резюме, что усложняет процесс резюмирования.\n",
    "3. **Сложность языка:** Научные статьи часто используют специализированный язык и термины.\n",
    "4. **Объем статей:** Некоторые статьи очень длинные и содержат ненужную информацию.\n",
    "\n",
    "**Аргумент к решению:** Для решения этих проблем необходимо разработать функционал для обработки различных форматов документов и методов предобработки текста (например, очистка от лишних символов и форматирование).\n",
    "\n",
    "# МЕТРИКИ ОЦЕНИВАНИЯ КАЧЕСТВА РЕЗЮМИРОВАНИЯ\n",
    "\n",
    "Для оценки качества резюмирования можно использовать следующие метрики:\n",
    "\n",
    "## 1. ROUGE (Recall-Oriented Understudy for Gisting Evaluation)\n",
    "\n",
    "- **ROUGE-N:** Измеряет совпадение n-грамм между резюме и оригинальной статьей.\n",
    "- **ROUGE-L:** Оценивает длину наибольшей общей последовательности (LCS) между резюме и оригиналом.\n",
    "\n",
    "**Аргумент к решению:** Эти метрики широко используются в автоматическом резюмировании и позволяют оценить качество резюме на основе совпадений с оригинальным текстом (Lin, 2004).\n",
    "\n",
    "## 2. BLEU (Bilingual Evaluation Understudy)\n",
    "\n",
    "Измеряет качество перевода, но также может применяться к резюмированию, оценивая совпадения n-грамм.\n",
    "\n",
    "**Аргумент к решению:** BLEU помогает оценить точность резюме в передаче информации из оригинала, хотя его применение в резюмировании менее эффективно по сравнению с ROUGE.\n",
    "\n",
    "## 3. METEOR (Metric for Evaluation of Translation with Explicit Ordering)\n",
    "\n",
    "METEOR учитывает синонимы и морфологические изменения, что делает его более чувствительным к смыслу текста.\n",
    "\n",
    "**Аргумент к решению:** Эта метрика полезна для оценки семантики и помогает избежать потери смысла при автоматическом резюмировании.\n",
    "\n",
    "### Человеческая оценка\n",
    "\n",
    "Проведение опросов среди экспертов или целевой аудитории для качественной оценки резюме с вопросами о полноте, ясности и релевантности информации.\n",
    "\n",
    "**Аргумент к решению:** Человеческая оценка позволяет получить качественную обратную связь и выявить аспекты, которые могут быть не учтены автоматическими метриками.\n",
    "\n",
    "# Заключение\n",
    "\n",
    "Для разработки MVP web-приложения для резюмирования научных статей необходимо учитывать языковое разнообразие и тематику статей, а также проблемы с данными. Использование метрик ROUGE, BLEU и METEOR в сочетании с человеческой оценкой позволит создать эффективный инструмент для автоматического резюмирования, что обеспечит высокое качество резюме и удовлетворит потребности пользователей из разных областей науки.\n",
    "\n",
    "---\n",
    "\n",
    "### Ссылки:\n",
    "- [ROUGE (metric)](https://en.wikipedia.org/wiki/ROUGE_(metric))\n",
    "- [Влияние отзывов на мнение потребителя](https://vc.ru/marketing/91417-issledovanie-vliyanie-otzyvov-na-mnenie-potrebitelya)\n",
    "- [Публикации на разных языках в индексах цитирования](https://www.unkniga.ru/kultura/8295-publikatsii-na-raznyh-yazykah-v-indeksah-tsitirvaniya-est-li-shans.html)\n",
    "- [Области науки и их виды](https://zaochnik-com.com/spravochnik/filosofija/filosofija-nauki/oblasti-nauki-i-ih-vidy/)\n",
    "- [BLEU Evaluation Metric](https://www.educative.io/answers/what-is-the-bleu-evaluation-metric)\n",
    "- [METEOR Evaluation Metric](https://huggingface.co/spaces/evaluate-metric/meteor/blob/main/README.md)\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c41e5b7-020d-4ab0-ba32-390143687a90",
   "metadata": {},
   "source": [
    "# Источники данных для обучения (dataset)\n",
    "\n",
    "Наиболее подходящие датасеты для обучения суммаризатора научных статей включают:\n",
    "\n",
    "- **PubMed и PMC (PubMed Central):** большие датасеты из биомедицинских статей, широко используемые для задач по обработке медицинских текстов.\n",
    "- **ArXiv:** содержит научные статьи по физике, математике, информатике и другим областям.\n",
    "- **ScienceQA:** охватывает множество дисциплин, содержит полный текст статей и рефераты.\n",
    "- **SciTLDR:** датасет из сокращенных версий научных статей, сгенерированных вручную и автоматически.\n",
    "\n",
    "# Оценка моделей\n",
    "\n",
    "## BART\n",
    "\n",
    "- **ROUGE-N и ROUGE-L:** Модель показала хорошие результаты по основным метрикам, но уступила более специализированным моделям, таким как Pegasus и Gemma2.\n",
    "- **BLEU и METEOR:** Производительность на BLEU и METEOR также была стабильной, но не выдающейся, особенно на длинных научных текстах, где модель иногда теряла точность в передаче смысловых блоков.\n",
    "- **Вывод:** Хороший вариант для задач общей суммаризации, но не лучший для научных текстов.\n",
    "\n",
    "## T5\n",
    "\n",
    "- **ROUGE-N и ROUGE-L:** Универсальность T5 делает её полезной для разных задач, но показатели ROUGE ниже, чем у Gemma2 и Pegasus.\n",
    "- **BLEU и METEOR:** Результаты на уровне BART; модель справляется с точной передачей информации, но не всегда способна выделять ключевые термины в научных статьях.\n",
    "- **Вывод:** Удобна для широкого спектра задач, но уступает в точности для специализированного научного текста.\n",
    "\n",
    "## Pegasus\n",
    "\n",
    "- **ROUGE-N и ROUGE-L:** Достигает высоких показателей ROUGE, особенно при обобщении содержательного текста, но иногда теряет ключевые научные термины и важные подробности.\n",
    "- **BLEU и METEOR:** Значения выше, чем у T5 и BART, но результаты по METEOR показывают, что модель иногда недооценивает синонимию и структуру сложных текстов.\n",
    "- **Вывод:** Pegasus силен в суммаризации, но требует доработки для научных текстов, чтобы лучше передавать сложные детали и терминологию.\n",
    "\n",
    "## Gemma2\n",
    "\n",
    "- **ROUGE-N и ROUGE-L:** Gemma2 лидирует по этим метрикам, показывая точное перекрытие с контрольными суммаризациями и лучшее понимание структуры научных текстов.\n",
    "- **BLEU и METEOR:** Превосходит все остальные модели на BLEU и METEOR, обеспечивая наилучшую точность и корректную передачу синонимических структур, что важно для специализированного языка.\n",
    "- **Вывод:** Лучшая модель для суммаризации научных статей благодаря стабильности, точности и высокому качеству передачи информации.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
